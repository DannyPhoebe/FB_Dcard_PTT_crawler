{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests,re\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "\n",
    "header = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36'}\n",
    "\n",
    "def page_load(url):\n",
    "    results = requests.get(url,headers=header,verify=True)\n",
    "    return json.loads(results.text)\n",
    "\n",
    "\n",
    "class FB_crawler(object):\n",
    "    def __init__(self, page_id, start, until, token, sleep=True):\n",
    "        self.page_id = page_id if type(page_id) == str else str(page_id)\n",
    "        self.start = start\n",
    "        self.until = until\n",
    "        self.token = token\n",
    "        self.sleep = sleep\n",
    "        self.post_ids = []\n",
    "        self.url_num = None\n",
    "        self.data = dict()\n",
    "        print(\"Facebook_crawler is activated...\")\n",
    "\n",
    "\n",
    "    def pid_collector(self):\n",
    "        query = '%s/posts?fields=name,link,full_picture,message&limit=100&since=%s&until=%s' % (self.page_id,self.start,self.until)\n",
    "        posts = page_load(\"https://graph.facebook.com/v2.8/%s&access_token=%s\"%(query, self.token))\n",
    "        while len(posts['data']) > 0:\n",
    "            self.post_ids.append(list(map(lambda x:x['id'],posts['data'])))\n",
    "            posts = page_load(posts['paging']['next'])\n",
    "        self.post_ids = sum(self.post_ids,[])\n",
    "        self.url_num = len(self.post_ids)\n",
    "        print(self.url_num,\"post urls are collected\")\n",
    "\n",
    "                                 \n",
    "    def crawler(self):\n",
    "        assert len(self.post_ids) > 0,'please run pid_collector first or reset the search period'\n",
    "        self.data['info'] = {'start':self.start,'until':self.until}\n",
    "        self.data['post'] = [None]*self.url_num\n",
    "        for p_idx,pid in enumerate(self.post_ids):\n",
    "            # start comment crawler\n",
    "            if p_idx % 20 == 0: print('crawling post {}...'.format(p_idx))\n",
    "            com_query = r'%s?fields=name,description,link,message,comments' % (pid)\n",
    "            com = page_load(\"https://graph.facebook.com/v2.8/%s&access_token=%s\" % (com_query, self.token))\n",
    "            self.data['post'][p_idx] = com\n",
    "            while True: # restart gate for comment crawler\n",
    "                try:\n",
    "                    while 'paging' in com and 'next' in com['paging']:\n",
    "                        com = page_load(com['paging']['next'])\n",
    "                        self.data['post'][p_idx]['comments']['data'].append(com['data'])\n",
    "                except:\n",
    "                    print('retry')\n",
    "                    time.sleep(5)\n",
    "                    pass\n",
    "                else:\n",
    "                    break\n",
    "            # start reaction crawler\n",
    "            tmp = dict()\n",
    "            for idx,rxn_type in enumerate(['ANGRY','SAD','LOVE','HAHA','WOW','LIKE']):\n",
    "                rxn_query = '%s?fields=reactions.type(%s).summary(true)' % (pid,rxn_type)\n",
    "                rxn = page_load(\"https://graph.facebook.com/v2.8/%s&access_token=%s\" % (rxn_query, self.token)) \n",
    "                try:\n",
    "                    tmp[rxn_type] = rxn['reactions']['summary']['total_count']\n",
    "                except KeyError:\n",
    "                    tmp[rxn_type] = None\n",
    "            self.data['post'][p_idx]['reaction'] = tmp\n",
    "            if p_idx % 100 == 0:\n",
    "                time.sleep(5)\n",
    "        with open('result.json', 'w', encoding='utf-8') as fp:\n",
    "            json.dump(self.data, fp)\n",
    "        print('process complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facebook_crawler is activated...\n",
      "(9, 'post urls are collected')\n",
      "crawling post 0...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'encoding' is an invalid keyword argument for this function",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-29aee9afa5ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFB_crawler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'232633627068'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'17-01-01'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'17-01-12'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid_collector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrawler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-f341f80e70ad>\u001b[0m in \u001b[0;36mcrawler\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mp_idx\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'result.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m             \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'process complete.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'encoding' is an invalid keyword argument for this function"
     ]
    }
   ],
   "source": [
    "token='EAAL5c1c0Nk4BABeQs4AZCkxCTWjYiy7QCzpfN8o7Stc9JrWZCelYkZBCelfg4WOv2pGDX1U6XZCx1NavxaweBqc4CcOel9hSexj060Fo0F8eLYWZCSkZBKgOgBUz7ZB526id2ZCkrsoMfTGlIEQSMOwh5W01CWlkNWMZD&expires=5184000'\n",
    "c = FB_crawler('232633627068','17-01-01','17-01-12',token)\n",
    "c.pid_collector()\n",
    "c.crawler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WOW': 57, 'HAHA': 112, 'ANGRY': 18, 'SAD': 2, 'LIKE': 2539, 'LOVE': 13}\n"
     ]
    }
   ],
   "source": [
    "print(c.data['post'][132]['reaction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "覺得日本站務人員好辛苦T__T #天編\n",
      "　\n",
      "【完整 #動新聞】塞爆也不管！日電車男邊玩手機邊硬上\n",
      "http://www.appledaily.com.tw/actionnews/appledaily/7/20170101/1024722/\n",
      "　\n",
      "【圖文報導】\n",
      "http://www.appledaily.com.tw/realtimenews/article/strange/20170101/1024722\n",
      "　\n"
     ]
    }
   ],
   "source": [
    "print c.data['post']"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
